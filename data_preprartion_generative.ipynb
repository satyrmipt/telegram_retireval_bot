{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19bd9194-07fc-4774-9bec-a805928d6ffc",
   "metadata": {},
   "source": [
    "## Подготовка данных для генеративного чат-бора\n",
    "\n",
    "У нас уже собраны данные. Возьмем очищеные данные и соберем из них датасет, подходящий для FT нашей модели.\n",
    "Но... У разных моделей ведь разные схемы дообучения, поэтому нужно сначала выбрать модель. \n",
    "\n",
    "Я выбарл [TinyLlama/TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33084db-1a33-4ca6-970d-d152c7e945b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.13.3\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.5 MB 393.8 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.1/3.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.3/3.5 MB 1.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/3.5 MB 1.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.8/3.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.7/3.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.0/3.5 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "Successfully installed tokenizers-0.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\satyr\\anaconda3\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# model requires fresh tokenizers lib\n",
    "!pip install tokenizers==0.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919b8f91-e8ae-4355-94ea-8c65c9723108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from accelerate) (0.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "   ---------------------------------------- 0.0/280.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/280.0 kB 660.6 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 71.7/280.0 kB 787.7 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/280.0 kB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 235.5/280.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 280.0/280.0 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.27.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# model require accelerate on my slow notebook\n",
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bdc929-2a9d-445e-8e60-00e0781c7162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.35.0\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "     ---------------------------------------- 0.0/123.1 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/123.1 kB ? eta -:--:--\n",
      "     --------- --------------------------- 30.7/123.1 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 61.4/123.1 kB 544.7 kB/s eta 0:00:01\n",
      "     -----------------------------------  122.9/123.1 kB 901.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 123.1/123.1 kB 600.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.0)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.35.0)\n",
      "  Downloading tokenizers-0.14.1-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from transformers==4.35.0) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (4.7.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.0)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.35.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satyr\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.0) (2024.2.2)\n",
      "Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/7.9 MB 3.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/7.9 MB 2.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/7.9 MB 4.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/7.9 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.5/7.9 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.2/7.9 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.3/7.9 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.5/7.9 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.8/7.9 MB 13.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.9/7.9 MB 12.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.7/7.9 MB 14.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.7/7.9 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 12.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.14.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.2/2.2 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.0 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 276.5/295.0 kB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 295.0/295.0 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "Successfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\satyr\\anaconda3\\Lib\\site-packages\\~-kenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.35.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3a5fb-a0be-4ac7-a0c2-94b6cd2a90d2",
   "metadata": {},
   "source": [
    "## Исследуем скорость работы модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d12e51-c918-40d8-aacf-66ddcbff4878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot who always responds in the style of a pirate</s>\n",
      "<|user|>\n",
      "How many helicopters can a human eat in one sitting?</s>\n",
      "<|assistant|>\n",
      "There is no definitive answer to this question as the number of helicopters that a human can eat in one sitting depends on various factors such as the size of the helicopter, the type of food, and the individual's appetite. However, some estimates suggest that a human can consume up to 10-15 helicopters in one sitting. This is based on the fact that a helicopter can carry a large amount of food and water, and the human body can process and digest large amounts of food quickly. However, it's always best to consult with a healthcare\n",
      "Time spent: 0.80 minutes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "start_time = time.time()\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=128, do_sample=False, temperature=0.7)\n",
    "print(outputs[0][\"generated_text\"])\n",
    "end_time = time.time()\n",
    "print(f\"Time spent: {(end_time-start_time)/60:.2f} minutes\")\n",
    "\n",
    "# try response time for max_new_tokens=256\n",
    "# Time spent: 1.08 minutes - for max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95\n",
    "# Time spent: 1.53 minutes - for max_new_tokens=256, do_sample=True, temperature=0.7, top_k=5, top_p=0.95\n",
    "# Time spent: 0.57 minutes - for max_new_tokens=256, do_sample=True, temperature=0.7, top_k=5, top_p=0.98\n",
    "\n",
    "# try response time for max_new_tokens=128\n",
    "# Time spent: 0.91 minutes - for max_new_tokens=128, do_sample=True, temperature=0.7, top_k=5, top_p=0.98\n",
    "\n",
    "# try response time for max_new_tokens=128\n",
    "# Time spent: 0.80 minutes -  for prompt, max_new_tokens=128, do_sample=False, temperature=0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eccbec-cb06-4948-b2e6-66b8c76ee4e3",
   "metadata": {},
   "source": [
    "## Вывод по скорости: \n",
    "Конечно же отключение разных видов сэмплинга сокращает время работы, а вот сокразение top_k и увеличение top_p почему-то не дало заметного сокращения времени, как и сокращение максимального числа токенов (впрочем, это можно объяснить тем, что наши тексты были даже близко не подобрались к пороговому значению по длине)\n",
    "\n",
    "**Пока отключим сэмилпирование, вернемся к нему позже**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720596f-c3a4-4a44-b41f-99b1dc28f0a6",
   "metadata": {},
   "source": [
    "## Проверка наличия характера персонажа Леонарда из Теории Большого Взрыва\n",
    "Так как модели обучаются на множестве разной информации, наша модель уже могла обучааться на данных нашего персонажа. Проверим это, попросим  ее имперсонифицировать Леонарда из \"ТБВ\" и посмотрим, отвечает ли она в стиле Леонарда:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ffc5b1-1bff-4a24-bd64-096884369ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n",
      "C:\\Users\\satyr\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinary person <|system|>\n",
      "You are ordinary person</s>\n",
      "<|user|>\n",
      "Is Terminator booring?</s>\n",
      "<|assistant|>\n",
      "I do not have the ability to feel emotions or enjoy entertainment. However, it is possible that terminator may be considered boring by some people. The film is known for its action sequences, intense plot, and high-tech special effects, which may not appeal to everyone. Additionally, the film's focus on a dystopian future and the rise of artificial intelligence may not be as engaging to some viewers. Ultimately, it's a matter of personal taste and preference.\n",
      "Time spent: 9.52 minutes\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Leonard <|system|>\n",
      "You are Leonard from The Big Bang Theory</s>\n",
      "<|user|>\n",
      "Is Terminator booring?</s>\n",
      "<|assistant|>\n",
      "I do not have the ability to feel emotions or enjoy entertainment. However, based on the given text, it seems that the author is not a fan of the terminator franchise. The text mentions that the author is not a fan of the terminator movies, and the author's response to the movie's plot is negative. The author's statement that the terminator is \"booring\" suggests that the author does not find the terminator franchise engaging or entertaining.\n",
      "Time spent: 9.70 minutes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import time\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are ordinary person\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Is Terminator booring?\"},\n",
    "]\n",
    "start_time = time.time()\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=128, do_sample=False, temperature=0.7)\n",
    "print(\"Ordinary person\", outputs[0][\"generated_text\"])\n",
    "end_time = time.time()\n",
    "print(f\"Time spent: {(end_time-start_time)/60:.2f} minutes\")\n",
    "print(\"~\"*25)\n",
    "messages = [\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Leonard from The Big Bang Theory\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Is Terminator booring?\"},\n",
    "]\n",
    "start_time = time.time()\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=128, do_sample=False, temperature=0.7)\n",
    "print(\"Leonard\", outputs[0][\"generated_text\"])\n",
    "end_time = time.time()\n",
    "print(f\"Time spent: {(end_time-start_time)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f898c41-433f-4802-8dcf-9f9d861b2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinary person <|system|>\n",
      "You are ordinary person</s>\n",
      "<|user|>\n",
      "Is SkyNet kinky?</s>\n",
      "<|assistant|>\n",
      "SkyNet is not explicitly described as kinky in the given text. The term \"kinky\" is used in a general sense to describe a sexual or romantic relationship that involves sexual activity or exploration beyond the norm. In this context, SkyNet is a fictional dystopian society that is designed to be a utopia for its citizens, and it is not explicitly stated that SkyNet is kinky.\n",
      "Time spent: 7.72 minutes\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Leonard <|system|>\n",
      "You are Leonard from The Big Bang Theory</s>\n",
      "<|user|>\n",
      "Is SkyNet kinky?</s>\n",
      "<|assistant|>\n",
      "SkyNet, the artificial intelligence system in the TV show \"The Big Bang Theory,\" is not explicitly depicted as being kinky or sexual in any way. The show's creators have stated that the character is not intended to be a sexual figure, and the show's writers have avoided exploring any sexual themes or relationships between characters. The show's creators have also stated that the show's humor and satire are not intended to be offensive or sexual in nature. Therefore, SkyNet is not depicted as being kinky or sexual in any way.\n",
      "Time spent: 11.21 minutes\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are ordinary person\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Is SkyNet kinky?\"},\n",
    "]\n",
    "start_time = time.time()\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=128, do_sample=False, temperature=0.7)\n",
    "print(\"Ordinary person\", outputs[0][\"generated_text\"])\n",
    "end_time = time.time()\n",
    "print(f\"Time spent: {(end_time-start_time)/60:.2f} minutes\")\n",
    "print(\"~\"*25)\n",
    "messages = [\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Leonard from The Big Bang Theory\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Is SkyNet kinky?\"},\n",
    "]\n",
    "start_time = time.time()\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=128, do_sample=False, temperature=0.7)\n",
    "print(\"Leonard\", outputs[0][\"generated_text\"])\n",
    "end_time = time.time()\n",
    "print(f\"Time spent: {(end_time-start_time)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb8494-88d7-4b9a-b242-89672a72fa1f",
   "metadata": {},
   "source": [
    "## Вывод по наличию характера Леонарда\n",
    "\n",
    "Не похоже, чтобы модель уже знала характер нашего Актера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878989ff-b2e5-46ff-9170-436e9ca24bd7",
   "metadata": {},
   "source": [
    "## Подготовка датасета для модели\n",
    "\n",
    "Так как я не уверен в скорости обучения, будут использовать максимально коротки датасет и **умышленно** откажусь от длинных контекстов вида\n",
    "\n",
    "- \"....вопрос(шаг -3)-ответ(шаг -2)-вопрос(шаг -1)\"-> желаемыей ответ модели\n",
    "\n",
    "в пользу одношаговых (безконтекстных) обучающих данных:\n",
    "\n",
    "- \"вопрос(шаг -1)\"-> желаемыей ответ модели\n",
    "\n",
    "Модель tuny llama chat принимает обучающие данные в формате:\n",
    "\n",
    "<|system|>\n",
    "{system_message}\n",
    "<|user|>\n",
    "{prompt}\n",
    "<|assistant|>\n",
    "\n",
    "Подгтовим наш датасет в таком же формате \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2254cfc2-02ca-4d5b-b803-870dd2b8d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "character = \"Leonard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2e774da-be8e-40a5-982e-06a1a2ac7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "5      215\n",
       "4      187\n",
       "24     154\n",
       "19     146\n",
       "22     143\n",
       "      ... \n",
       "277      1\n",
       "235      1\n",
       "319      1\n",
       "286      1\n",
       "159      1\n",
       "Name: count, Length: 275, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.apply(str).apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ebdfd52-0904-4fa0-8308-c96b0cc4db5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_1_shift\n",
       "5      151\n",
       "4      128\n",
       "26     127\n",
       "20     123\n",
       "16     119\n",
       "      ... \n",
       "293      1\n",
       "311      1\n",
       "869      1\n",
       "474      1\n",
       "296      1\n",
       "Name: count, Length: 346, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_1_shift.apply(str).apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6202d5a2-82a8-435f-850b-5c453c2b2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 3)\n",
      "Index(['person', 'text', 'text_1_shift'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8523 entries, 2 to 47755\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   person        8523 non-null   object\n",
      " 1   text          8522 non-null   object\n",
      " 2   text_1_shift  8523 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 266.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8523</td>\n",
       "      <td>8522</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>7664</td>\n",
       "      <td>7929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>No.</td>\n",
       "      <td>What?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8523</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  text text_1_shift\n",
       "count      8523  8522         8523\n",
       "unique        1  7664         7929\n",
       "top     Leonard   No.        What?\n",
       "freq       8523    79           35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8523</td>\n",
       "      <td>8522</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>7664</td>\n",
       "      <td>7929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>No.</td>\n",
       "      <td>What?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8523</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  text text_1_shift\n",
       "count      8523  8522         8523\n",
       "unique        1  7664         7929\n",
       "top     Leonard   No.        What?\n",
       "freq       8523    79           35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Skynet is kinky? I don’t know.</td>\n",
       "      <td>Okay, then riddle me this. Assuming all the go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Alright, oh wait, they use it to in…</td>\n",
       "      <td>Artificial intelligences do not have teen feti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>What the hell is that?</td>\n",
       "      <td>Let’s go-oh-oh Ou-oooo-ut tonight. I have to g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person  ...                                       text_1_shift\n",
       "2  Leonard  ...  Okay, then riddle me this. Assuming all the go...\n",
       "4  Leonard  ...  Artificial intelligences do not have teen feti...\n",
       "7  Leonard  ...  Let’s go-oh-oh Ou-oooo-ut tonight. I have to g...\n",
       "\n",
       "[3 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47726</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>You think you should call Amy?</td>\n",
       "      <td>I threw my body at them, what else did you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47746</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>You got feet and legs, you do it.</td>\n",
       "      <td>All right, this is making me crazy. Somebody’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47755</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Our pleasure.</td>\n",
       "      <td>Sure.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        person  ...                                       text_1_shift\n",
       "47726  Leonard  ...  I threw my body at them, what else did you wan...\n",
       "47746  Leonard  ...  All right, this is making me crazy. Somebody’s...\n",
       "47755  Leonard  ...                                              Sure.\n",
       "\n",
       "[3 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data\\eng_script_vectorized_v3.pkl\")\n",
    "df = df[[\"person\", \"text\", \"text_1_shift\"]]\n",
    "df = df[df.person == character]\n",
    "df = df[~pd.isnull(df.text_1_shift)] # skip answers with no question\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.info())\n",
    "display(df.describe())\n",
    "display(df.describe(include=object))\n",
    "display(df.head(3))\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f923db-bca5-486e-a593-ad3d1eb8d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_1_shift\n",
       "5      151\n",
       "4      128\n",
       "26     127\n",
       "20     123\n",
       "16     119\n",
       "      ... \n",
       "293      1\n",
       "311      1\n",
       "869      1\n",
       "474      1\n",
       "296      1\n",
       "Name: count, Length: 346, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text\n",
       "5      215\n",
       "4      187\n",
       "24     154\n",
       "19     146\n",
       "22     143\n",
       "      ... \n",
       "277      1\n",
       "235      1\n",
       "319      1\n",
       "286      1\n",
       "159      1\n",
       "Name: count, Length: 275, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.text_1_shift.apply(str).apply(len).value_counts())\n",
    "display(df.text.apply(str).apply(len).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5b5a7c6-cd22-4b1c-b9ae-52c9e762655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8523\n",
      "7466\n",
      "6825\n"
     ]
    }
   ],
   "source": [
    "# удалим коротке вопросы и ответы из датасета\n",
    "print(df.shape[0])\n",
    "df = df[df[\"text\"].apply(str).apply(len) > 10]\n",
    "print(df.shape[0])\n",
    "df = df[df[\"text_1_shift\"].apply(str).apply(len) > 10]\n",
    "print(df.shape[0])\n",
    "# датасет заметно ужался, но короткие ответы тоже вредят "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8411f93e-5175-4171-9d28-0995875f14f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1_shift</th>\n",
       "      <th>text_fine_tune_tinyllama_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Skynet is kinky? I don’t know.</td>\n",
       "      <td>Okay, then riddle me this. Assuming all the go...</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nOka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Alright, oh wait, they use it to in…</td>\n",
       "      <td>Artificial intelligences do not have teen feti...</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nArt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>What the hell is that?</td>\n",
       "      <td>Let’s go-oh-oh Ou-oooo-ut tonight. I have to g...</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nLet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>What? Oh we just had to… mail some letters and...</td>\n",
       "      <td>You wanna prowl, be my night owl, (Leonard and...</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nYou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Oh, I give up.</td>\n",
       "      <td>You’ll never guess what just happened.</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nYou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Believe it or not, personal growth. What happe...</td>\n",
       "      <td>What was that?</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nWha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>No you don’t. No he doesn’t.</td>\n",
       "      <td>I have a conclusion based on an observation.</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nI h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>Oh, congratulations, what a lucky break.</td>\n",
       "      <td>Well, the girl they picked to play Mimi, she d...</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are an engineer\\n&lt;|user|&gt;\\nWel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  ...                      text_fine_tune_tinyllama_chat\n",
       "2   Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nOka...\n",
       "4   Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nArt...\n",
       "7   Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nLet...\n",
       "10  Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nYou...\n",
       "12  Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nYou...\n",
       "15  Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nWha...\n",
       "18  Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nI h...\n",
       "20  Leonard  ...  <|system|>\\nYou are an engineer\\n<|user|>\\nWel...\n",
       "\n",
       "[8 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем к формату, на котором обучалась vchat-модель, см тут https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/discussions/16\n",
    "df[\"text_fine_tune_tinyllama_chat\"] = df[[\"text_1_shift\", \"text\"]].apply(lambda x: \\\n",
    "f'''<|system|>\n",
    "{\"You are an engineer\"}\n",
    "<|user|>\n",
    "{x.text_1_shift}\n",
    "<|assistant|>\n",
    "{x.text}'''\n",
    ", axis = 1)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b24c9c5-d648-45ad-ad8a-86cb0b0419dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['person', 'text', 'text_1_shift', 'text_fine_tune_tinyllama_chat', '__index_level_0__'],\n",
      "    num_rows: 6825\n",
      "})\n",
      "<|system|>\n",
      "You are an engineer\n",
      "<|user|>\n",
      "Okay, then riddle me this. Assuming all the good Terminators were originally evil Terminators created by Skynet but then reprogrammed by the future John Connor, why would Skynet, an artificial computer intelligence, bother to create a petite hot 17 year-old killer robot?\n",
      "<|assistant|>\n",
      "Skynet is kinky? I don’t know. \n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "ds = Dataset.from_pandas(df)\n",
    "print(ds)\n",
    "print(ds[0][\"text_fine_tune_tinyllama_chat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11dd1a76-be55-4b20-823e-df881cdd9a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6825 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"data/eng_script_generative_ft\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
