# telegram_retireval_bot
Англоязычный (!) Телеграм-бор https://t.me/TBB_chat_bot использует retrieval-подход или generative-подход для ответа на вопросы в стиле Леонарда из "Теории большого взрыва". Прежде чем отправлять сообщения боту, его нужно запустить. Одновременный запуск двух ботов не тестировался, но почти точно он работать не будет. Прошу запускать либо retieval либо generative-бота, но не обоих сразу.

Видео работы retrieval-бота: https://www.youtube.com/watch?v=G6ERmRTcXT0. Бот загружает векторизованную базу и дообученные модели bi- и cross-энкодера с HuggingFace, это может занять время. В случае проблем с загрузкой, прошу сообщить (или в пачку или в whatsapp +7 966 325 60 78) и я передам данные и модель через гугл-диск. Однако, не ожидаю проблем, так как работа с HF тестировалась мной! 

Видео работы generative-бота: https://www.youtube.com/watch?v=UxMhAukmsSg.

И retrieval и generative бот игнорируют все сообщения, отправленные до его запуска (это one line настройка, которую я отключил из-за неудобства при отладке, так что прошу не снижать балл за эту настройку как за признак того, что бот не асинхронный). Для запуска перейдите в папку проекта и выполните команду:

  * python main_retrieval.py
или
  * python main_generative.py
    
retrieval: бот запущен бот в конфигурации bi-encoder + cross-encoder
generative: бот будет запущен на базе fine tuned модели Tiny Llama Chat v1.0

Чтобы убедиться, что бот работает, отправьте ему после запуска "hello" без кавычек: бот ответит на это сообщение не запуская механизма retrieval\generate.

Для запуска бота необходимы пакеты, перечисленые в requirements.txt. Некоторые из них я установил через conda forge. Так же необходимо прописать путь к моим личным модулям: my_tokenize_vectorize.py, my_bot.py или выложить их в папку, где их увидит python.



Файлы проекта для retrieval-бота:

 * data_preparation.ipynb: сбор данных из интернета, изучение, обогащение
 * data_vectorization.ipynb: обогащение данных векторизованными представлениями вопросов и ответов, использованы два подхода: glove-вкторизация (без дообучения посредством mittens) и Sentence BERT векоризация (взят предобученный энкодер и дообучен на triple loss)
 * bi_enc_cross_enc_fine_tuning.ipynb: ноутбку с дообучением модели BI-энкодера и Cross-энкодера.
 * my_tokenize_vectorize.py: мой модуль, содержит класс токенайзера и два класса векторизации (glove и SBERT)
 * my_bot.py: мой модуль, содержит инстурменты поиска ответа на вопрос
 * main_retrieval.py: исполняемый файл проекта, описывает устройство телеграм-бота.
 * Отчет Retrieval Левакин А.В..odt - отчет о проекте

Файлы проекта для generative-бота:

 * data_preparation_generative.ipynb: подготовка ранее собранных данных для fine tuning модели
 * tinyllama_ft.ipynb: доменное дообучение модели, выбор параметров дообучения и параметров генерации (самая интересная часть проекта)
 * my_generative_bot.py: именно этот модуль отвечаает за запуск LLM и генерацию ответа
 * main_generative.py: исполняемый файл проекта, описывает устройство телеграм-бота.
 * Отчет Retrieval Левакин А.В..odt - отчет о проекте
